{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VhRPjYDHVn83",
        "outputId": "f0b19502-4c34-4bcc-a304-c99ce93e07e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "06x9sdlsV3fz"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from keras import layers\n",
        "from keras.callbacks import Callback, ModelCheckpoint, ReduceLROnPlateau\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import pandas as pd\n",
        "import scipy\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "from collections import Counter\n",
        "import json\n",
        "import itertools\n",
        "from keras.layers import Dense,Dropout,Activation,Add,MaxPooling2D,Conv2D,Flatten,BatchNormalization\n",
        "import os\n",
        "from PIL import Image\n",
        "import cv2\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, roc_curve,roc_auc_score, auc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1AnTCWlV-dC"
      },
      "source": [
        "Data Gathering and Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oGLJZn_HV_TX",
        "outputId": "b45137b4-b266-4fb5-82f9-a1a6cccdb1f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 6006 images belonging to 2 classes.\n",
            "Found 2000 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "# create data generator\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    zoom_range=0.1,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "# Define the data generator for the validation and test sets\n",
        "val_test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# fit the model on data\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/Group_Project_Data/Train',\n",
        "    target_size=(64,64),\n",
        "    batch_size=32,\n",
        "    class_mode='binary')\n",
        "    \n",
        "validation_generator = val_test_datagen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/Group_Project_Data/Valid',\n",
        "    target_size=(64,64),\n",
        "    batch_size=32,\n",
        "    class_mode='binary')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "PJ32i_LqWEGI"
      },
      "outputs": [],
      "source": [
        "def Dataset_loader(DIR, RESIZE, sigmaX=10):\n",
        "    IMG = []\n",
        "    read = lambda imname: np.asarray(Image.open(imname).convert(\"RGB\"))\n",
        "    \n",
        "    for root, _, files in os.walk(DIR):\n",
        "        for file in files:\n",
        "            if file.endswith('.png'):\n",
        "                PATH = os.path.join(root,file)\n",
        "\n",
        "                img = read(PATH)\n",
        "\n",
        "                img = cv2.resize(img, (RESIZE,RESIZE))\n",
        "\n",
        "                IMG.append(np.array(img))\n",
        "    return IMG\n",
        "\n",
        "real_train = np.array(Dataset_loader('/content/drive/MyDrive/Group_Project_Data/Train/Real',64))\n",
        "fake_train = np.array(Dataset_loader('/content/drive/MyDrive/Group_Project_Data/Train/Fake',64))\n",
        "real_test = np.array(Dataset_loader('/content/drive/MyDrive/Group_Project_Data/Valid/Real',64))\n",
        "fake_test = np.array(Dataset_loader('/content/drive/MyDrive/Group_Project_Data/Valid/Fake',64))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "hB2jDsV-WKtF"
      },
      "outputs": [],
      "source": [
        "# Create labels\n",
        "real_train_label = np.ones(len(real_train))\n",
        "fake_train_label = np.zeros(len(fake_train))\n",
        "real_test_label = np.ones(len(real_test))\n",
        "fake_test_label = np.zeros(len(fake_test))\n",
        "\n",
        "# Merge data \n",
        "X_train = np.concatenate((real_train, fake_train), axis = 0)\n",
        "Y_train = np.concatenate((real_train_label, fake_train_label), axis = 0)\n",
        "X_test = np.concatenate((real_test, fake_test), axis = 0)\n",
        "Y_test = np.concatenate((real_test_label, fake_test_label), axis = 0)\n",
        "\n",
        "# Shuffle train data\n",
        "s = np.arange(X_train.shape[0])\n",
        "np.random.shuffle(s)\n",
        "X_train = X_train[s]\n",
        "Y_train = Y_train[s]\n",
        "\n",
        "# Shuffle test data\n",
        "s = np.arange(X_test.shape[0])\n",
        "np.random.shuffle(s)\n",
        "X_test = X_test[s]\n",
        "Y_test = Y_test[s]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WrgkAeYZWOT4"
      },
      "source": [
        "Define Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I09u4sktWPUR",
        "outputId": "d8b5ecc2-1677-4e59-e43c-200b2d149056"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 62, 62, 8)         224       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 31, 31, 8)        0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 29, 29, 16)        1168      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 14, 14, 16)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 12, 12, 32)        4640      \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 6, 6, 32)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1152)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 16)                18448     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 16)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 24,497\n",
            "Trainable params: 24,497\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# define input shape\n",
        "input_shape = (64, 64, 3)\n",
        "\n",
        "# define model architecture\n",
        "model = tf.keras.Sequential([\n",
        "    layers.Conv2D(8, (3, 3), activation='relu', input_shape=input_shape),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(16, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(16, activation='relu'),\n",
        "    layers.Dropout(0.5), # Adding Dropout layer with a rate of 0.5\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "q02_-xkdWVQ7"
      },
      "outputs": [],
      "source": [
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, verbose=1)\n",
        "\n",
        "#define the model checkpoint callback this will keep on saving the model as a physical file\n",
        "model_checkpoint = ModelCheckpoint('cnn.h5', verbose=1, save_best_only=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4nnAodDEWY3y"
      },
      "source": [
        "Train Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "jdH1jKPCWZ1E"
      },
      "outputs": [],
      "source": [
        "#define a function to fit the model\n",
        "def fit_and_evaluate(train, test, EPOCHS=20, BATCH_SIZE=32):\n",
        "\n",
        "    results = model.fit(train, epochs=EPOCHS, batch_size=BATCH_SIZE, callbacks=[early_stopping, model_checkpoint], \n",
        "              verbose=1, validation_data=test) \n",
        "    \n",
        "    print(\"Val Score: \", model.evaluate(test))\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJxWOM1ElFvZ",
        "outputId": "c56e4d27-f22b-48a7-dd31-8401e12c872c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on Fold:  1\n",
            "Epoch 1/20\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.3557 - accuracy: 0.8160\n",
            "Epoch 1: val_loss improved from inf to 0.02162, saving model to cnn.h5\n",
            "188/188 [==============================] - 38s 196ms/step - loss: 0.3557 - accuracy: 0.8160 - val_loss: 0.0216 - val_accuracy: 0.9940\n",
            "Epoch 2/20\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.1154 - accuracy: 0.9542\n",
            "Epoch 2: val_loss improved from 0.02162 to 0.01622, saving model to cnn.h5\n",
            "188/188 [==============================] - 37s 197ms/step - loss: 0.1154 - accuracy: 0.9542 - val_loss: 0.0162 - val_accuracy: 0.9950\n",
            "Epoch 3/20\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.0883 - accuracy: 0.9589\n",
            "Epoch 3: val_loss did not improve from 0.01622\n",
            "188/188 [==============================] - 36s 193ms/step - loss: 0.0883 - accuracy: 0.9589 - val_loss: 0.0200 - val_accuracy: 0.9930\n",
            "Epoch 4/20\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.0829 - accuracy: 0.9619\n",
            "Epoch 4: val_loss did not improve from 0.01622\n",
            "188/188 [==============================] - 37s 196ms/step - loss: 0.0829 - accuracy: 0.9619 - val_loss: 0.0165 - val_accuracy: 0.9965\n",
            "Epoch 5/20\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.0804 - accuracy: 0.9610\n",
            "Epoch 5: val_loss improved from 0.01622 to 0.01414, saving model to cnn.h5\n",
            "188/188 [==============================] - 41s 220ms/step - loss: 0.0804 - accuracy: 0.9610 - val_loss: 0.0141 - val_accuracy: 0.9990\n",
            "Epoch 6/20\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.0714 - accuracy: 0.9654\n",
            "Epoch 6: val_loss did not improve from 0.01414\n",
            "188/188 [==============================] - 41s 220ms/step - loss: 0.0714 - accuracy: 0.9654 - val_loss: 0.0167 - val_accuracy: 0.9985\n",
            "Epoch 7/20\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.0654 - accuracy: 0.9709\n",
            "Epoch 7: val_loss did not improve from 0.01414\n",
            "188/188 [==============================] - 38s 204ms/step - loss: 0.0654 - accuracy: 0.9709 - val_loss: 0.0380 - val_accuracy: 0.9895\n",
            "Epoch 8/20\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.0616 - accuracy: 0.9682\n",
            "Epoch 8: val_loss did not improve from 0.01414\n",
            "188/188 [==============================] - 38s 200ms/step - loss: 0.0616 - accuracy: 0.9682 - val_loss: 0.0180 - val_accuracy: 0.9990\n",
            "Epoch 8: early stopping\n",
            "63/63 [==============================] - 6s 88ms/step - loss: 0.0180 - accuracy: 0.9990\n",
            "Val Score:  [0.017964275553822517, 0.9990000128746033]\n",
            "====================================================================================\n",
            "\n",
            "\n",
            "Training on Fold:  2\n",
            "Epoch 1/20\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.0498 - accuracy: 0.9667\n",
            "Epoch 1: val_loss did not improve from 0.01414\n",
            "188/188 [==============================] - 37s 194ms/step - loss: 0.0498 - accuracy: 0.9667 - val_loss: 0.0148 - val_accuracy: 0.9990\n",
            "Epoch 2/20\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.0523 - accuracy: 0.9662\n",
            "Epoch 2: val_loss did not improve from 0.01414\n",
            "188/188 [==============================] - 37s 199ms/step - loss: 0.0523 - accuracy: 0.9662 - val_loss: 0.0209 - val_accuracy: 0.9980\n",
            "Epoch 3/20\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.0459 - accuracy: 0.9720\n",
            "Epoch 3: val_loss did not improve from 0.01414\n",
            "188/188 [==============================] - 37s 199ms/step - loss: 0.0459 - accuracy: 0.9720 - val_loss: 0.0171 - val_accuracy: 0.9990\n",
            "Epoch 4/20\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.0461 - accuracy: 0.9695\n",
            "Epoch 4: val_loss did not improve from 0.01414\n",
            "188/188 [==============================] - 36s 192ms/step - loss: 0.0461 - accuracy: 0.9695 - val_loss: 0.0183 - val_accuracy: 0.9985\n",
            "Epoch 4: early stopping\n",
            "63/63 [==============================] - 6s 91ms/step - loss: 0.0183 - accuracy: 0.9985\n",
            "Val Score:  [0.018307078629732132, 0.9984999895095825]\n",
            "====================================================================================\n",
            "\n",
            "\n",
            "Training on Fold:  3\n",
            "Epoch 1/20\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.0447 - accuracy: 0.9669\n",
            "Epoch 1: val_loss did not improve from 0.01414\n",
            "188/188 [==============================] - 36s 192ms/step - loss: 0.0447 - accuracy: 0.9669 - val_loss: 0.0213 - val_accuracy: 0.9990\n",
            "Epoch 2/20\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.0479 - accuracy: 0.9672\n",
            "Epoch 2: val_loss did not improve from 0.01414\n",
            "188/188 [==============================] - 37s 197ms/step - loss: 0.0479 - accuracy: 0.9672 - val_loss: 0.0206 - val_accuracy: 0.9985\n",
            "Epoch 3/20\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.0538 - accuracy: 0.9645\n",
            "Epoch 3: val_loss did not improve from 0.01414\n",
            "188/188 [==============================] - 41s 219ms/step - loss: 0.0538 - accuracy: 0.9645 - val_loss: 0.0164 - val_accuracy: 0.9990\n",
            "Epoch 4/20\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.0353 - accuracy: 0.9727\n",
            "Epoch 4: val_loss did not improve from 0.01414\n",
            "188/188 [==============================] - 42s 221ms/step - loss: 0.0353 - accuracy: 0.9727 - val_loss: 0.0194 - val_accuracy: 0.9985\n",
            "Epoch 5/20\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.0445 - accuracy: 0.9649\n",
            "Epoch 5: val_loss did not improve from 0.01414\n",
            "188/188 [==============================] - 36s 193ms/step - loss: 0.0445 - accuracy: 0.9649 - val_loss: 0.0214 - val_accuracy: 0.9985\n",
            "Epoch 6/20\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.0301 - accuracy: 0.9739\n",
            "Epoch 6: val_loss improved from 0.01414 to 0.01328, saving model to cnn.h5\n",
            "188/188 [==============================] - 36s 193ms/step - loss: 0.0301 - accuracy: 0.9739 - val_loss: 0.0133 - val_accuracy: 0.9985\n",
            "Epoch 7/20\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.0236 - accuracy: 0.9967\n",
            "Epoch 7: val_loss did not improve from 0.01328\n",
            "188/188 [==============================] - 36s 193ms/step - loss: 0.0236 - accuracy: 0.9967 - val_loss: 0.0141 - val_accuracy: 0.9995\n",
            "Epoch 8/20\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.0253 - accuracy: 0.9962\n",
            "Epoch 8: val_loss did not improve from 0.01328\n",
            "188/188 [==============================] - 35s 187ms/step - loss: 0.0253 - accuracy: 0.9962 - val_loss: 0.0176 - val_accuracy: 0.9990\n",
            "Epoch 9/20\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.0240 - accuracy: 0.9958\n",
            "Epoch 9: val_loss did not improve from 0.01328\n",
            "188/188 [==============================] - 44s 232ms/step - loss: 0.0240 - accuracy: 0.9958 - val_loss: 0.0297 - val_accuracy: 0.9985\n",
            "Epoch 9: early stopping\n",
            "63/63 [==============================] - 5s 73ms/step - loss: 0.0297 - accuracy: 0.9985\n",
            "Val Score:  [0.02969924360513687, 0.9984999895095825]\n",
            "====================================================================================\n",
            "\n",
            "\n",
            "Training on Fold:  4\n",
            "Epoch 1/20\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.0213 - accuracy: 0.9952\n",
            "Epoch 1: val_loss did not improve from 0.01328\n",
            "188/188 [==============================] - 38s 202ms/step - loss: 0.0213 - accuracy: 0.9952 - val_loss: 0.0214 - val_accuracy: 0.9995\n",
            "Epoch 2/20\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.0143 - accuracy: 0.9962\n",
            "Epoch 2: val_loss did not improve from 0.01328\n",
            "188/188 [==============================] - 36s 192ms/step - loss: 0.0143 - accuracy: 0.9962 - val_loss: 0.0175 - val_accuracy: 0.9990\n",
            "Epoch 3/20\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.0107 - accuracy: 0.9988\n",
            "Epoch 3: val_loss did not improve from 0.01328\n",
            "188/188 [==============================] - 36s 192ms/step - loss: 0.0107 - accuracy: 0.9988 - val_loss: 0.0180 - val_accuracy: 0.9990\n",
            "Epoch 4/20\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.0072 - accuracy: 0.9992\n",
            "Epoch 4: val_loss did not improve from 0.01328\n",
            "188/188 [==============================] - 37s 196ms/step - loss: 0.0072 - accuracy: 0.9992 - val_loss: 0.0192 - val_accuracy: 0.9990\n",
            "Epoch 5/20\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.0098 - accuracy: 0.9987\n",
            "Epoch 5: val_loss did not improve from 0.01328\n",
            "188/188 [==============================] - 37s 195ms/step - loss: 0.0098 - accuracy: 0.9987 - val_loss: 0.0248 - val_accuracy: 0.9980\n",
            "Epoch 5: early stopping\n",
            "63/63 [==============================] - 5s 73ms/step - loss: 0.0248 - accuracy: 0.9980\n",
            "Val Score:  [0.02483685500919819, 0.9980000257492065]\n",
            "====================================================================================\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "n_folds=4\n",
        "\n",
        "#save the model history in a list after fitting so that we can plot later\n",
        "model_history = [] \n",
        "\n",
        "for i in range(n_folds):\n",
        "    print(\"Training on Fold: \",i+1)\n",
        "\n",
        "    model_history.append(fit_and_evaluate(train_generator,validation_generator))\n",
        "    \n",
        "    print(\"=======\"*12, end=\"\\n\\n\\n\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}