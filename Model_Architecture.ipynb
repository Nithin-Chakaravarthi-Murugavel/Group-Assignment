{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VA6VjLaqTbwe",
        "outputId": "c1c843f4-fa19-4ab5-b220-01aadd4e82ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras import layers\n",
        "from keras.callbacks import Callback, ModelCheckpoint, ReduceLROnPlateau\n",
        "from keras.models import Sequential\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "from keras.layers import Dense,Dropout,Activation,Add,MaxPooling2D,Conv2D,Flatten,BatchNormalization\n",
        "import os\n",
        "from PIL import Image\n",
        "import cv2\n"
      ],
      "metadata": {
        "id": "wFrOqtp5TgYK"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Gathering and Preprocessing"
      ],
      "metadata": {
        "id": "JZSPQFZuTvYe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create data generator\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    zoom_range=0.1,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "# Define the data generator for the validation and test sets\n",
        "val_test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# fit the model on data\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/Group_Project_Data 2/Group_Project_Data/Train',\n",
        "    target_size=(64,64),\n",
        "    batch_size=32,\n",
        "    class_mode='binary')\n",
        "    \n",
        "validation_generator = val_test_datagen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/Group_Project_Data 2/Group_Project_Data/Valid',\n",
        "    target_size=(64,64),\n",
        "    batch_size=32,\n",
        "    class_mode='binary')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TgRQragaTzLQ",
        "outputId": "c833a66d-11d8-4f8c-cd60-f414407864c8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 6000 images belonging to 2 classes.\n",
            "Found 2000 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def Dataset_loader(DIR, RESIZE, sigmaX=10):\n",
        "    IMG = []\n",
        "    read = lambda imname: np.asarray(Image.open(imname).convert(\"RGB\"))\n",
        "    \n",
        "    for root, _, files in os.walk(DIR):\n",
        "        for file in files:\n",
        "            if file.endswith('.png'):\n",
        "                PATH = os.path.join(root,file)\n",
        "\n",
        "                img = read(PATH)\n",
        "\n",
        "                img = cv2.resize(img, (RESIZE,RESIZE))\n",
        "\n",
        "                IMG.append(np.array(img))\n",
        "    return IMG\n",
        "\n",
        "real_train = np.array(Dataset_loader('/content/drive/MyDrive/Group_Project_Data 2/Group_Project_Data/Train/Real',64))\n",
        "fake_train = np.array(Dataset_loader('/content/drive/MyDrive/Group_Project_Data 2/Group_Project_Data/Train/Fake',64))\n",
        "real_test = np.array(Dataset_loader('/content/drive/MyDrive/Group_Project_Data 2/Group_Project_Data/Valid/Real',64))\n",
        "fake_test = np.array(Dataset_loader('/content/drive/MyDrive/Group_Project_Data 2/Group_Project_Data/Valid/Fake',64))"
      ],
      "metadata": {
        "id": "RqqEKFSXUeiY"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split dataset"
      ],
      "metadata": {
        "id": "4pQo9TrCUk9r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create labels\n",
        "real_train_label = np.ones(len(real_train))\n",
        "fake_train_label = np.zeros(len(fake_train))\n",
        "real_test_label = np.ones(len(real_test))\n",
        "fake_test_label = np.zeros(len(fake_test))\n",
        "\n",
        "# Merge data \n",
        "X_train = np.concatenate((real_train, fake_train), axis = 0)\n",
        "Y_train = np.concatenate((real_train_label, fake_train_label), axis = 0)\n",
        "X_test = np.concatenate((real_test, fake_test), axis = 0)\n",
        "Y_test = np.concatenate((real_test_label, fake_test_label), axis = 0)\n",
        "\n",
        "# Shuffle train data\n",
        "s = np.arange(X_train.shape[0])\n",
        "np.random.shuffle(s)\n",
        "X_train = X_train[s]\n",
        "Y_train = Y_train[s]\n",
        "\n",
        "# Shuffle test data\n",
        "s = np.arange(X_test.shape[0])\n",
        "np.random.shuffle(s)\n",
        "X_test = X_test[s]\n",
        "Y_test = Y_test[s]\n"
      ],
      "metadata": {
        "id": "VrqchUCVUm_G"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define Model Architecture"
      ],
      "metadata": {
        "id": "_M-SmRfG9gMB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define input shape\n",
        "input_shape = (64, 64, 3)\n",
        "\n",
        "# define model architecture\n",
        "model = tf.keras.Sequential([\n",
        "    layers.Conv2D(8, (3, 3), activation='relu', input_shape=input_shape),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(16, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(16, activation='relu'),\n",
        "    layers.Dropout(0.5), # Adding Dropout layer with a rate of 0.5\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rhg04dY19kp6",
        "outputId": "95416688-29d6-43d8-dbda-e21f6dfbee5f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_9 (Conv2D)           (None, 62, 62, 8)         224       \n",
            "                                                                 \n",
            " max_pooling2d_9 (MaxPooling  (None, 31, 31, 8)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 29, 29, 16)        1168      \n",
            "                                                                 \n",
            " max_pooling2d_10 (MaxPoolin  (None, 14, 14, 16)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 12, 12, 32)        4640      \n",
            "                                                                 \n",
            " max_pooling2d_11 (MaxPoolin  (None, 6, 6, 32)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 1152)              0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 16)                18448     \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 16)                0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 24,497\n",
            "Trainable params: 24,497\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    }
  ]
}